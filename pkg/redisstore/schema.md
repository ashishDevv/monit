Perfect timing to do this.
Youâ€™re absolutely right: **Redis is now a core system of record (hot state)**, so its schema must be **intentional, minimal, and explainable**.

Iâ€™ll do this like a **Redis design doc** youâ€™d see in a real backend team.

---

# ğŸ§  First: Redis Design Principles (WHY before WHAT)

Before keys, lock these rules in:

### Rule 1 â€” Redis stores **HOT, mutable, real-time state**

* Things that change often
* Things needed for live dashboards
* Things needed for fast decisions

### Rule 2 â€” Redis data must be:

* **O(1)** to read/write
* **Easy to delete/reset**
* **Recoverable** from DB if lost

### Rule 3 â€” Redis NEVER stores long-term truth

Postgres does.

---

# ğŸ“¦ Entities we will store in Redis

You identified them correctly:

1. **Scheduler data (monitors)**
2. **Success results (last check)**
3. **Incident state (current incident)**
4. **Retry state**

Now letâ€™s design each **cleanly and minimally**.

---

# 1ï¸âƒ£ Monitor Scheduler (Time-based jobs)

## Purpose

Answer:

> â€œWhich monitors should run next, and when?â€

## Data structure

### âœ… **Sorted Set (ZSET)**

Because:

* Time ordering
* Range queries
* Atomic pop (`ZPOPMIN`)

---

## Key

```text
monitor:schedule
```

## Member

```text
<monitor_id>
```

## Score

```text
next_run_unix_timestamp
```

---

## Example

```text
ZADD monitor:schedule 1705305600 monitor_123
```

---

## Access pattern

| Operation        | Redis command                 |
| ---------------- | ----------------------------- |
| Claim due jobs   | `ZPOPMIN monitor:schedule N`  |
| Reschedule       | `ZADD monitor:schedule ts id` |
| Retry scheduling | `ZADD monitor:schedule ts id` |

âœ” Atomic
âœ” Multi-instance safe
âœ” Scales to millions

---

# 2ï¸âƒ£ Success Result (Last known good state)

## Purpose

Answer:

> â€œIs this monitor UP right now? What was the last latency?â€

Used by:

* Live dashboard
* Status API
* Health summaries

---

## Data structure

### âœ… **Hash**

Why hash?

* Fixed fields
* Partial updates
* Compact memory usage

---

## Key

```text
monitor:status:<monitor_id>
```

## Fields

```text
status_code     â†’ int
latency_ms      â†’ int
checked_at      â†’ unix_ts
```

---

## Example

```text
HSET monitor:status:monitor_123 \
  status_code 200 \
  latency_ms 120 \
  checked_at 1705305661
```

### Optional

```text
EXPIRE monitor:status:monitor_123 300
```

(So dead monitors donâ€™t lie forever)

---

## Access pattern

| Use case         | Redis                         |
| ---------------- | ----------------------------- |
| Dashboard status | `HGETALL monitor:status:<id>` |
| Batch dashboard  | `MGET / pipeline`             |
| Overwrite        | `HSET`                        |

âœ” Fast
âœ” Cheap
âœ” Read-heavy optimized

---

# 3ï¸âƒ£ Incident State (MOST IMPORTANT PART)

## Purpose

Answer:

> â€œIs this monitor currently failing? How many consecutive failures?â€

This is **NOT history**.
This is **current reality**.

---

## Data structure

### âœ… **Hash**

Why?

* Multiple related fields
* Atomic increments
* Easy delete on recovery

---

## Key

```text
monitor:incident:<monitor_id>
```

## Fields

```text
failure_count       â†’ int
first_failure_at    â†’ unix_ts
last_failure_at     â†’ unix_ts
alerted             â†’ bool
```

---

## Example

```text
HINCRBY monitor:incident:monitor_123 failure_count 1
HSET monitor:incident:monitor_123 last_failure_at 1705305670
```

---

## On first failure

```text
HSETNX first_failure_at now
```

---

## On success

```text
DEL monitor:incident:<monitor_id>
```

This **resets consecutive failure tracking**.

---

## Access pattern

| Use case          | Redis                |
| ----------------- | -------------------- |
| Increment failure | `HINCRBY`            |
| Check threshold   | `HGET failure_count` |
| Alert dedupe      | `HGET alerted`       |
| Close incident    | `DEL`                |

âœ” No DB reads
âœ” No race conditions
âœ” Easy reset

---

# 4ï¸âƒ£ Retry State (Transient scheduling metadata)

## Purpose

Answer:

> â€œHow many times has this monitor been retried for the *current check window*?â€

Retry is:

* Temporary
* Small
* Reset on success

---

## Data structure

### âœ… **Simple String or Hash**

Weâ€™ll use **String** for minimalism.

---

## Key

```text
monitor:retry:<monitor_id>
```

## Value

```text
retry_count (int)
```

## TTL

```text
EXPIRE 300 seconds
```

So retries auto-reset.

---

## Example

```text
INCR monitor:retry:monitor_123
EXPIRE monitor:retry:monitor_123 300
```

---

## On success

```text
DEL monitor:retry:<monitor_id>
```

---

## Access pattern

| Use case          | Redis  |
| ----------------- | ------ |
| Increment retry   | `INCR` |
| Check retry count | `GET`  |
| Reset             | `DEL`  |

âœ” Simple
âœ” Bounded
âœ” No DB dependency

---

# ğŸ” How all of this fits together (flow recap)

### Failure occurs

1. Increment retry (if retryable)
2. If retry limit not exceeded â†’ reschedule
3. Else:

   * Increment incident failure_count
   * Possibly alert
   * Possibly write incident start to DB

---

### Success occurs

1. Write success status hash
2. Delete retry key
3. If incident exists:

   * Close incident in DB
   * Delete incident hash

---

# ğŸ“Š Live Dashboard (IMPORTANT)

## What dashboard needs

* Current UP/DOWN
* Latency
* Failure count (if DOWN)
* Last check time

---

## Redis-only reads (FAST)

For each monitor:

```text
HGETALL monitor:status:<id>
HGETALL monitor:incident:<id> (optional)
```

If incident key exists â†’ DOWN
Else â†’ UP

---

## Batch dashboard optimization

For list pages:

* Use Redis pipelining
* Avoid N+1 DB queries
* Redis can handle this easily

---

# ğŸ§  Why this Redis schema is excellent

| Property        | Result                |
| --------------- | --------------------- |
| Clear ownership | Each key has one job  |
| Low memory      | Hashes + ints         |
| Fast            | O(1) ops              |
| Recoverable     | DB is source of truth |
| Debuggable      | Human-readable keys   |
| Interview-ready | Easy to explain       |

---

# ğŸ”’ Final mental model (remember this)

* **ZSET** â†’ *When should something happen?*
* **Hash (status)** â†’ *What is the last known state?*
* **Hash (incident)** â†’ *Is something currently wrong?*
* **String (retry)** â†’ *Are we validating uncertainty?*

If you can explain *this Redis design*, you can design **any real-time backend system**.

---

If you want next, we can:

* Design Redis memory usage estimates
* Design eviction & TTL strategy
* Design cold-start recovery
* Design dashboard APIs
* Design alert deduplication keys

Just say the word ğŸ‘‡
